{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! unzip /content/qg_train.zip\n",
        "! rm /content/qg_train.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvrZYpjV8FwZ",
        "outputId": "15ce0ef0-e5a3-44ce-cb5e-e2363d56477d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open /content/qg_train.zip, /content/qg_train.zip.zip or /content/qg_train.zip.ZIP.\n",
            "rm: cannot remove '/content/qg_train.zip': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bbwl6E1E205R",
        "outputId": "044ab592-806e-4086-e2d3-1aa24b90fd1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.21.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n"
          ]
        }
      ],
      "source": [
        "%pip install transformers\n",
        "# T5Tokenizer requires the SentencePiece library\n",
        "%pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install datasets\n",
        "%pip install rouge_score\n",
        "%pip install sacrebleu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8V0fO8RwA8cC",
        "outputId": "46d97f96-1e7e-40a3-e3c4-ad717c5cb73a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (2.4.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.12.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.13)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.7.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.8.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.7.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.7.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.7/dist-packages (0.1.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from rouge_score) (3.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rouge_score) (1.21.6)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from rouge_score) (1.15.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from rouge_score) (1.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk->rouge_score) (4.64.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk->rouge_score) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk->rouge_score) (7.1.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk->rouge_score) (2022.6.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.7/dist-packages (2.2.0)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu) (0.8.10)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu) (2022.6.2)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.7/dist-packages (from sacrebleu) (2.5.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from sacrebleu) (1.21.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from sacrebleu) (4.9.1)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from sacrebleu) (0.4.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wB441x104K-o"
      },
      "outputs": [],
      "source": [
        "# Importing libraries\n",
        "import os\n",
        "import logging\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# Import modules from huggingface\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "OUTPUT_DIR = \"./outputs/\"\n",
        "if not os.path.exists(OUTPUT_DIR):\n",
        "  os.mkdir(OUTPUT_DIR)\n",
        "\n",
        "# define logging\n",
        "\n",
        "LOG_FILE = OUTPUT_DIR + f\"t5_finetuning_{np.datetime64('now')}\"\n",
        "logging.basicConfig(filename=LOG_FILE, filemode=\"w\", level=logging.DEBUG)"
      ],
      "metadata": {
        "id": "QG3Q0E-jKHOZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tlYaKW9h4ai_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "849dbfd4-75e4-4559-cfa3-cc22ede4e5c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2Gn4rTgENb8"
      },
      "source": [
        "### Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y6nEben93JAk"
      },
      "outputs": [],
      "source": [
        "INPUT_DIR = \"./data/\"\n",
        "train_df = pd.read_csv(INPUT_DIR+\"qg_train.csv\")\n",
        "dev_df = pd.read_csv(INPUT_DIR+\"qg_dev.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AYfBicZQ59Jf"
      },
      "outputs": [],
      "source": [
        "# for question generation task, prepend answer to sentence\n",
        "train_df[\"input\"] = \"answer: \"+train_df[\"answer\"]+\" context: \"+train_df[\"context\"]\n",
        "dev_df[\"input\"] = \"answer: \"+dev_df[\"answer\"]+\" context: \"+dev_df[\"context\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "81f4PKa1F6aM",
        "outputId": "91979606-57e6-41a6-d8ab-a31d1be358ca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            question               answer  \\\n",
              "0           When did Beyonce start becoming popular?    in the late 1990s   \n",
              "1  What areas did Beyonce compete in when she was...  singing and dancing   \n",
              "2  When did Beyonce leave Destiny's Child and bec...                 2003   \n",
              "3      In what city and state did Beyonce  grow up?        Houston, Texas   \n",
              "4         In which decade did Beyonce become famous?           late 1990s   \n",
              "\n",
              "                                            sentence  \\\n",
              "0  Born and raised in Houston, Texas, she perform...   \n",
              "1  Born and raised in Houston, Texas, she perform...   \n",
              "2  Their hiatus saw the release of Beyoncé's debu...   \n",
              "3  Born and raised in Houston, Texas, she perform...   \n",
              "4  Born and raised in Houston, Texas, she perform...   \n",
              "\n",
              "                                             context  \\\n",
              "0  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
              "1  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
              "2  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
              "3  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
              "4  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
              "\n",
              "                                               input  \n",
              "0  answer: in the late 1990s context: Beyoncé Gis...  \n",
              "1  answer: singing and dancing context: Beyoncé G...  \n",
              "2  answer: 2003 context: Beyoncé Giselle Knowles-...  \n",
              "3  answer: Houston, Texas context: Beyoncé Gisell...  \n",
              "4  answer: late 1990s context: Beyoncé Giselle Kn...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a87dcc14-d123-4382-9ccf-c92f6b5f55f6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>sentence</th>\n",
              "      <th>context</th>\n",
              "      <th>input</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>When did Beyonce start becoming popular?</td>\n",
              "      <td>in the late 1990s</td>\n",
              "      <td>Born and raised in Houston, Texas, she perform...</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>answer: in the late 1990s context: Beyoncé Gis...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What areas did Beyonce compete in when she was...</td>\n",
              "      <td>singing and dancing</td>\n",
              "      <td>Born and raised in Houston, Texas, she perform...</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>answer: singing and dancing context: Beyoncé G...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>When did Beyonce leave Destiny's Child and bec...</td>\n",
              "      <td>2003</td>\n",
              "      <td>Their hiatus saw the release of Beyoncé's debu...</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>answer: 2003 context: Beyoncé Giselle Knowles-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>In what city and state did Beyonce  grow up?</td>\n",
              "      <td>Houston, Texas</td>\n",
              "      <td>Born and raised in Houston, Texas, she perform...</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>answer: Houston, Texas context: Beyoncé Gisell...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>In which decade did Beyonce become famous?</td>\n",
              "      <td>late 1990s</td>\n",
              "      <td>Born and raised in Houston, Texas, she perform...</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>answer: late 1990s context: Beyoncé Giselle Kn...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a87dcc14-d123-4382-9ccf-c92f6b5f55f6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a87dcc14-d123-4382-9ccf-c92f6b5f55f6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a87dcc14-d123-4382-9ccf-c92f6b5f55f6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsfoZbjqENcC",
        "outputId": "7a83854b-e046-4889-ddcb-1316e766a87a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training (69247, 3) samples\n",
            "Validation (17312, 3) samples\n",
            "Test (5920, 3) samples\n"
          ]
        }
      ],
      "source": [
        "logging.info(f\"[Data]: Reading data...\\n\")\n",
        "\n",
        "source_text = \"input\"\n",
        "target_text = \"question\"\n",
        "\n",
        "train_dataset = train_df.reset_index()[[source_text,target_text]]\n",
        "test_dataset = dev_df.reset_index()[[source_text,target_text]]\n",
        "\n",
        "# train test split \n",
        "# SQuaD 2.0 train --> 80% train + 20% val\n",
        "# SQuaD 2.0 dev --> test\n",
        "train_dataset, val_dataset = train_test_split(train_dataset, test_size=0.2, random_state=42)\n",
        "\n",
        "# reset dataframe index\n",
        "train_dataset.reset_index(inplace=True)\n",
        "val_dataset.reset_index(inplace=True)\n",
        "test_dataset.reset_index(inplace=True)\n",
        "\n",
        "print(f\"Training {train_dataset.shape} samples\")\n",
        "print(f\"Validation {val_dataset.shape} samples\")\n",
        "print(f\"Test {test_dataset.shape} samples\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ho-HJA-6ENcD"
      },
      "source": [
        "### Define dataset class and functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8vLQPGAn4v17"
      },
      "outputs": [],
      "source": [
        "class QuestionSentenceDataset(Dataset):\n",
        "  \"\"\"\n",
        "  Creating a custom dataset \n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, data, tokenizer, source_len, target_len, source_text, target_text):\n",
        "    self.tokenizer = tokenizer\n",
        "    self.data = data\n",
        "    self.source_len = source_len\n",
        "    self.out_len = target_len\n",
        "    self.target_text = self.data[target_text]\n",
        "    self.source_text = self.data[source_text]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.target_text)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    source_text = str(self.source_text[index])\n",
        "    target_text = str(self.target_text[index])\n",
        "    \n",
        "    source_text = ' '.join(source_text.split())\n",
        "    target_text = ' '.join(target_text.split())\n",
        "\n",
        "    # from text to ids\n",
        "    source = self.tokenizer.batch_encode_plus([source_text], max_length= self.source_len, pad_to_max_length=True, truncation=True, padding=\"max_length\", return_tensors='pt')\n",
        "    target = self.tokenizer.batch_encode_plus([target_text], max_length= self.out_len, pad_to_max_length=True, truncation=True, padding=\"max_length\", return_tensors='pt')\n",
        "\n",
        "    source_ids = source['input_ids'].squeeze()\n",
        "    source_mask = source['attention_mask'].squeeze()\n",
        "    target_ids = target['input_ids'].squeeze()\n",
        "    target_mask = target['attention_mask'].squeeze()\n",
        "\n",
        "    return {\n",
        "        'source_ids': source_ids.to(dtype=torch.long), \n",
        "        'source_mask': source_mask.to(dtype=torch.long), \n",
        "        'target_ids': target_ids.to(dtype=torch.long),\n",
        "        'target_ids_y': target_ids.to(dtype=torch.long)\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nkj6wIMt40RK"
      },
      "outputs": [],
      "source": [
        "def train(epoch, tokenizer, model, device, loader, optimizer):\n",
        "\n",
        "  \"\"\"\n",
        "  Function for training\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  model.train()\n",
        "  epoch_loss = []\n",
        "  for _, data in tqdm(enumerate(loader)):\n",
        "    y = data['target_ids'].to(device, dtype = torch.long)\n",
        "    y_ids = y[:, :-1].contiguous()\n",
        "    lm_labels = y[:, 1:].clone().detach()\n",
        "    # padding of labels is done with a token with id -100\n",
        "    # which is a special token automatically ignored by PyTorch loss functions\n",
        "    lm_labels[y[:, 1:] == tokenizer.pad_token_id] = -100 \n",
        "    ids = data['source_ids'].to(device, dtype = torch.long)\n",
        "    mask = data['source_mask'].to(device, dtype = torch.long)\n",
        "\n",
        "    outputs = model(input_ids = ids, attention_mask = mask, decoder_input_ids=y_ids, labels=lm_labels)\n",
        "    loss = outputs[0]\n",
        "    epoch_loss.append(outputs[0].detach().cpu().numpy()) \n",
        "\n",
        "    # if _%10==0:\n",
        "    #   print(f\"Epoch {epoch}, Step {_}, Loss = {loss}\")\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()  \n",
        "\n",
        "  epoch_loss = np.mean(epoch_loss)\n",
        "\n",
        "  return epoch_loss "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUBykK-A43DF"
      },
      "outputs": [],
      "source": [
        "def validate(epoch, tokenizer, model, device, loader):\n",
        "\n",
        "  \"\"\"\n",
        "  Function for validation during training\n",
        "\n",
        "  \"\"\"\n",
        "  model.eval()\n",
        "  epoch_loss = []\n",
        "  with torch.no_grad():\n",
        "    for _, data in tqdm(enumerate(loader)):\n",
        "      y = data['target_ids'].to(device, dtype = torch.long)\n",
        "      y_ids = y[:, :-1].contiguous()\n",
        "      lm_labels = y[:, 1:].clone().detach()\n",
        "      lm_labels[y[:, 1:] == tokenizer.pad_token_id] = -100 \n",
        "      ids = data['source_ids'].to(device, dtype = torch.long)\n",
        "      mask = data['source_mask'].to(device, dtype = torch.long)\n",
        "\n",
        "      outputs = model(input_ids = ids, attention_mask = mask, decoder_input_ids=y_ids, labels=lm_labels)\n",
        "      loss = outputs[0]\n",
        "      epoch_loss.append(outputs[0].detach().cpu().numpy()) \n",
        "\n",
        "  epoch_loss = np.mean(epoch_loss)\n",
        "  return epoch_loss "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tw4RW_qO4_8T"
      },
      "outputs": [],
      "source": [
        "def T5Trainer(train_dataset, val_dataset, source_text, target_text, model_params, output_dir):\n",
        "  \n",
        "  \"\"\"\n",
        "  T5 train and validate\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  # for reproducibility\n",
        "  torch.manual_seed(model_params[\"SEED\"])\n",
        "  np.random.seed(model_params[\"SEED\"])\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "\n",
        "  logging.info(f\"\"\"[Model]: Loading {model_params[\"MODEL\"]}...\\n\"\"\")\n",
        "\n",
        "  # encode text\n",
        "  tokenizer = T5Tokenizer.from_pretrained(model_params[\"MODEL\"])\n",
        "\n",
        "  # using T5 with language model layer\n",
        "  model = T5ForConditionalGeneration.from_pretrained(model_params[\"MODEL\"])\n",
        "  model = model.to(device)\n",
        "  \n",
        "  # create dataloaders\n",
        "  train_qsd = QuestionSentenceDataset(train_dataset, tokenizer, \n",
        "                                      model_params[\"MAX_SOURCE_TEXT_LENGTH\"], model_params[\"MAX_TARGET_TEXT_LENGTH\"], \n",
        "                                      source_text, target_text)\n",
        "  \n",
        "  val_qsd = QuestionSentenceDataset(val_dataset, tokenizer, \n",
        "                                    model_params[\"MAX_SOURCE_TEXT_LENGTH\"], model_params[\"MAX_TARGET_TEXT_LENGTH\"], \n",
        "                                    source_text, target_text)\n",
        "\n",
        "  train_params = {\n",
        "      'batch_size': model_params[\"TRAIN_BATCH_SIZE\"],\n",
        "      'shuffle': True,\n",
        "      'num_workers': 0\n",
        "      }\n",
        "\n",
        "  val_params = {\n",
        "      'batch_size': model_params[\"VALID_BATCH_SIZE\"],\n",
        "      'shuffle': False,\n",
        "      'num_workers': 0\n",
        "      }\n",
        "\n",
        "  train_loader = DataLoader(train_qsd, **train_params)\n",
        "  val_loader = DataLoader(val_qsd, **val_params)\n",
        "\n",
        "  # training loop\n",
        "  train_loss = []\n",
        "  val_loss = []\n",
        "  optimizer = torch.optim.Adam(params =  model.parameters(), lr=model_params[\"LEARNING_RATE\"])\n",
        "\n",
        "  logging.info(f'[Initiating Fine Tuning]...\\n')\n",
        "\n",
        "  for epoch in range(model_params[\"TRAIN_EPOCHS\"]):\n",
        "      # train\n",
        "      epoch_train_loss = train(epoch, tokenizer, model, device, train_loader, optimizer)\n",
        "      train_loss.append(epoch_train_loss)\n",
        "      # validate\n",
        "      epoch_val_loss = validate(epoch, tokenizer, model, device, val_loader)\n",
        "      val_loss.append(epoch_val_loss)\n",
        "\n",
        "      print(f\"Epoch {epoch}, Train Loss = {round(epoch_train_loss, 3)} Val Loss = {round(epoch_val_loss, 3)}\")\n",
        "      # checkpoint\n",
        "      if epoch%10==0 and epoch>0:\n",
        "        cp_path = os.path.join(output_dir, f\"checkpoint{epoch}\")\n",
        "        model.save_pretrained(cp_path)\n",
        "      \n",
        "  plt.plot(list(zip(train_loss, val_loss)))\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.yticks(np.arange(0, 5, step=0.25))\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.xticks(np.arange(0, len(train_loss), step=1))\n",
        "  plt.legend(['train', 'val'])\n",
        "  plt.show()\n",
        "\n",
        "  logging.info(f\"[Saving Model]...\\n\")\n",
        "  # save model, tokenizer and configs\n",
        "  path = os.path.join(output_dir, \"final\")\n",
        "  model.save_pretrained(path)\n",
        "  tokenizer.save_pretrained(path)\n",
        "  \n",
        "  # logging.info(f\"[Validation Completed.]\\n\")\n",
        "  print(f\"\"\"[Model] Model saved @ {os.path.join(output_dir, \"checkpoints\")}\\n\"\"\")\n",
        "  # print(f\"\"\"[Validation] Generated questions saved @ {os.path.join(output_dir,'predictions.csv')}\\n\"\"\")\n",
        "  print(f\"\"\"[Logs] Logs saved @ {LOG_FILE}\\n\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PxCpQwD8PDIs"
      },
      "outputs": [],
      "source": [
        "model_params={\n",
        "    \"MODEL\":\"t5-small\",            # pretrained model\n",
        "    \"TRAIN_BATCH_SIZE\":8,          # training batch size\n",
        "    \"VALID_BATCH_SIZE\":8,          # validation batch size\n",
        "    \"TRAIN_EPOCHS\":3,              # number of training epochs\n",
        "    \"VAL_EPOCHS\":1,                # number of validation epochs\n",
        "    \"LEARNING_RATE\":5e-4,          # learning rate\n",
        "    \"MAX_SOURCE_TEXT_LENGTH\":75,   # max length of source text\n",
        "    \"MAX_TARGET_TEXT_LENGTH\":25,   # max length of target text\n",
        "    \"SEED\": 42                     # set seed for reproducibility \n",
        "\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        },
        "id": "qijZoYeI55fM",
        "outputId": "d6011cc3-0826-4a17-c81e-7ff3c3a8deef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/models/t5/tokenization_t5.py:174: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
            "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
            "- Be aware that you SHOULD NOT rely on t5-small automatically truncating your input to 512 when padding/encoding.\n",
            "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
            "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
            "  FutureWarning,\n",
            "8656it [11:09, 12.93it/s]\n",
            "2164it [01:03, 33.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Train Loss = 2.635999917984009 Val Loss = 2.3320000171661377\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "8656it [11:05, 13.00it/s]\n",
            "2164it [01:02, 34.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Train Loss = 2.3420000076293945 Val Loss = 2.2709999084472656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "8656it [11:04, 13.03it/s]\n",
            "2164it [01:02, 34.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Train Loss = 2.177000045776367 Val Loss = 2.253999948501587\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Model] Model saved @ ./outputs/checkpoints\n",
            "\n",
            "[Logs] Logs saved @ ./outputs/t5_finetuning_2022-08-04T13:02:34\n",
            "\n"
          ]
        }
      ],
      "source": [
        "T5Trainer(train_dataset, val_dataset, source_text=\"input\", target_text=\"question\", model_params=model_params, output_dir=OUTPUT_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation on test set"
      ],
      "metadata": {
        "id": "Xujjllw48MqD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_metric\n",
        "rouge_metric = load_metric(\"rouge\")\n",
        "bleu_metric = load_metric('sacrebleu')"
      ],
      "metadata": {
        "id": "KSFelb-L8RYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "rI3P0lvPBNJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(tokenizer, model, device, loader):\n",
        "\n",
        "  \"\"\"\n",
        "  Function to get predictions from model\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  model.eval()\n",
        "  sources = []\n",
        "  predictions = []\n",
        "  actuals = []\n",
        "  results = []\n",
        "  lengths = []\n",
        "  with torch.no_grad():\n",
        "      for _, data in tqdm(enumerate(loader)):\n",
        "          y = data['target_ids'].to(device, dtype = torch.long)\n",
        "          ids = data['source_ids'].to(device, dtype = torch.long)\n",
        "          mask = data['source_mask'].to(device, dtype = torch.long)\n",
        "\n",
        "          generated_ids = model.generate(\n",
        "              input_ids = ids,\n",
        "              attention_mask = mask, \n",
        "              max_length=25, \n",
        "              num_beams=2,\n",
        "              repetition_penalty=2.5, \n",
        "              length_penalty=1.0, \n",
        "              early_stopping=True\n",
        "              )\n",
        "\n",
        "          # get words from ids\n",
        "          srcs = [tokenizer.decode(i, skip_special_tokens=True, clean_up_tokenization_spaces=True) for i in ids]\n",
        "          preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n",
        "          target = [tokenizer.decode(t, skip_special_tokens=True, clean_up_tokenization_spaces=True)for t in y]\n",
        "          \n",
        "          # track generated length \n",
        "          lengths += [len(t) for t in target]\n",
        "          \n",
        "          # if _%10==0:\n",
        "          #     print(f'Completed {_}')\n",
        "\n",
        "          sources.extend(srcs)\n",
        "          predictions.extend(preds)\n",
        "          actuals.extend(target)\n",
        "      \n",
        "  # Compute ROUGE scores and extract ROUGE f1 scores\n",
        "  results = rouge_metric.compute(predictions=predictions, references=actuals, use_stemmer=True, use_aggregator=True)\n",
        "  results = {key: value.mid.fmeasure * 100 for key, value in results.items()}\n",
        "  # Compute BLEU scores\n",
        "  scores = bleu_metric.compute(predictions=predictions, references=[[a] for a in actuals]) #note: BLEU expects references to be list of lists\n",
        "  results[\"bleu_score\"] = scores[\"score\"]\n",
        "  # Average generated output length\n",
        "  results[\"gen_len\"] = np.mean(lengths)\n",
        "\n",
        "  results = {k: round(v, 4) for k, v in results.items()}\n",
        "  return predictions, actuals, sources, results"
      ],
      "metadata": {
        "id": "aFvKBjn69pG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_model_params={\n",
        "    \"MODEL_DIR\":\"./outputs/final/\",            \n",
        "    \"VALID_BATCH_SIZE\":8,          # evaluation batch size\n",
        "    \"MAX_SOURCE_TEXT_LENGTH\":75,   # max length of source text\n",
        "    \"MAX_TARGET_TEXT_LENGTH\":25,   # max length of target text\n",
        "    \"SEED\": 42                     # set seed for reproducibility \n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "zhNmSicbBqOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def T5Evaluator(val_dataset, source_text, target_text, model_params, output_dir):\n",
        "  \n",
        "  \"\"\"\n",
        "  T5 evaluate\n",
        "\n",
        "  \"\"\"\n",
        "   # for reproducibility\n",
        "  torch.manual_seed(model_params[\"SEED\"])\n",
        "  np.random.seed(model_params[\"SEED\"])\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  \n",
        "  logging.info(f\"\"\"[Model]: Loading our finetuned model from directory {model_params[\"MODEL_DIR\"]}...\\n\"\"\")\n",
        "\n",
        "  # encode text\n",
        "  tokenizer = T5Tokenizer.from_pretrained(model_params[\"MODEL_DIR\"])\n",
        "\n",
        "  # using T5 with language model layer\n",
        "  model = T5ForConditionalGeneration.from_pretrained(model_params[\"MODEL_DIR\"])\n",
        "  model = model.to(device)\n",
        "  \n",
        "  # create dataloaders\n",
        "  test_qsd = QuestionSentenceDataset(val_dataset, tokenizer, model_params[\"MAX_SOURCE_TEXT_LENGTH\"], model_params[\"MAX_TARGET_TEXT_LENGTH\"], source_text, target_text)\n",
        "\n",
        "  val_params = {\n",
        "      'batch_size': model_params[\"VALID_BATCH_SIZE\"],\n",
        "      'shuffle': False,\n",
        "      'num_workers': 0\n",
        "      }\n",
        "\n",
        "  test_loader = DataLoader(test_qsd, **val_params)\n",
        "\n",
        "  # evaluating test dataset\n",
        "  logging.info(f\"[Initiating Evaluation]...\\n\")\n",
        "  predictions, actuals, sources, results = evaluate(tokenizer, model, device, test_loader)\n",
        "  logging.info(f\"[Performance on Test Set] {results}\\n\")\n",
        "  print(\"Performance\", results)\n",
        "  final_df = pd.DataFrame({'generated':predictions,'actual':actuals, 'sentence': sources})\n",
        "  final_df.to_csv(os.path.join(output_dir,'predictions.csv'))\n",
        "  \n",
        "  logging.info(f\"[Evaluation Completed.]\\n\")\n",
        "  print(f\"\"\"[Evaluation] Generated questions saved @ {os.path.join(output_dir,'predictions.csv')}\\n\"\"\")"
      ],
      "metadata": {
        "id": "40YLBEts-YDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "T5Evaluator(test_dataset, source_text=\"input\", target_text=\"question\", model_params=my_model_params, output_dir=OUTPUT_DIR )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuwI1dUCC_2K",
        "outputId": "d8ac465b-be20-4a19-e529-54e56ff629db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "740it [08:36,  1.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performance {'rouge1': 32.6491, 'rouge2': 14.7086, 'rougeL': 29.7518, 'rougeLsum': 29.7411, 'bleu_score': 9.8088, 'gen_len': 61.1885}\n",
            "[Evaluation] Generated questions saved @ ./outputs/predictions.csv\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference for single sample\n"
      ],
      "metadata": {
        "id": "efTx-Q5eIrTm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def infer(tokenizer, model, device, data):\n",
        "\n",
        "  \"\"\"\n",
        "  Function to get predictions from model\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "      ids = data['source_ids'].to(device, dtype = torch.long)\n",
        "      mask = data['source_mask'].to(device, dtype = torch.long)\n",
        "\n",
        "      generated_ids = model.generate(\n",
        "          input_ids = ids,\n",
        "          attention_mask = mask, \n",
        "          max_length=25, \n",
        "          num_beams=2,\n",
        "          repetition_penalty=2.5, \n",
        "          length_penalty=1.0, \n",
        "          early_stopping=True\n",
        "          )\n",
        "\n",
        "      # get words from ids\n",
        "      prediction = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n",
        "    \n",
        "  return prediction"
      ],
      "metadata": {
        "id": "ZEf9CC3zXrZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def T5Inference(data, tokenizer, model, device, model_params):\n",
        "  \n",
        "  \"\"\"\n",
        "  T5 inference for a single sample\n",
        "  \"\"\"\n",
        "  def text2input(source_text, MAX_SOURCE_TEXT_LENGTH=75): \n",
        "    # prepare data\n",
        "    source_text = str(source_text)\n",
        "    source_text = ' '.join(source_text.split())\n",
        "    # from text to ids\n",
        "    source = tokenizer.batch_encode_plus([source_text], max_length=MAX_SOURCE_TEXT_LENGTH, pad_to_max_length=True, \n",
        "                                         truncation=True, padding=\"max_length\", return_tensors='pt')\n",
        "    source_ids = source['input_ids'].squeeze().view(1, -1)\n",
        "    source_mask = source['attention_mask'].squeeze().view(1, -1)\n",
        "    \n",
        "    return {'source_ids': source_ids.to(dtype=torch.long), 'source_mask': source_mask.to(dtype=torch.long)}\n",
        "\n",
        "  # generate question\n",
        "  input = text2input(data, model_params['MAX_SOURCE_TEXT_LENGTH'])\n",
        "  print(input['source_ids'].shape)\n",
        "  prediction = infer(tokenizer, model, device, input)\n",
        "  return prediction"
      ],
      "metadata": {
        "id": "ustozcrpXrZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "my_model_params = { \"MODEL_DIR\": \"./outputs/final/\", \n",
        "                   \"MAX_SOURCE_TEXT_LENGTH\": 75\n",
        "                   } \n",
        "\n",
        "# encode text\n",
        "tokenizer = T5Tokenizer.from_pretrained(my_model_params[\"MODEL_DIR\"])\n",
        "\n",
        "# using T5 with language model layer\n",
        "model = T5ForConditionalGeneration.from_pretrained(my_model_params[\"MODEL_DIR\"])\n",
        "model = model.to(device)  "
      ],
      "metadata": {
        "id": "rOgK2TOwJePC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare input\n",
        "answer = \"Lorentz's Law\"\n",
        "sentence = \"Through combining the definition of electric current as the time rate of change of electric charge, a rule of vector multiplication called Lorentz's Law describes the force on a charge moving in a magnetic field.\"\n",
        "qg_input = f\"answer: {answer} context: {sentence}\"\n",
        "\n",
        "# generate question\n",
        "T5Inference(qg_input, tokenizer, model, device, my_model_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxGPyAcuNA3j",
        "outputId": "c0586dd0-7bd8-4616-9d34-aae22d9e501b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 75])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['combines the definition of electric current as the time rate of change of electric charge?']"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! zip final.zip /content/outputs/final/*"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OANaIM9lQUmp",
        "outputId": "07d2fa29-6edc-4dcc-8484-7f4e84ad02bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/outputs/final/config.json (deflated 62%)\n",
            "  adding: content/outputs/final/pytorch_model.bin (deflated 7%)\n",
            "  adding: content/outputs/final/special_tokens_map.json (deflated 86%)\n",
            "  adding: content/outputs/final/spiece.model (deflated 48%)\n",
            "  adding: content/outputs/final/tokenizer_config.json (deflated 82%)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "t5_finetuning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.3 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.3"
    },
    "vscode": {
      "interpreter": {
        "hash": "f08154012ddadd8e950e6e9e035c7a7b32c136e7647e9b7c77e02eb723a8bedb"
      }
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}