{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Reference: https://www.sbert.net/examples/applications/retrieve_rerank/README.html"
      ],
      "metadata": {
        "id": "Xi2WZ4iP5_W9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVJ1lx3WoT2B",
        "outputId": "38f6c7e4-bf54-44bb-86af-f17ac48e8186"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from nltk import tokenize, sent_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6VmxeC9LoT2F"
      },
      "outputs": [],
      "source": [
        "# df = pd.read_pickle('data.df')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvQbMu1goT2F",
        "outputId": "39c17669-b503-4f68-964e-300761623a74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.7/dist-packages (2.2.2)\n",
            "Requirement already satisfied: rank_bm25 in /usr/local/lib/python3.7/dist-packages (0.2.2)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.12.0+cu113)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.7.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.64.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.8.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.0.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.1.96)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.13.0+cu113)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.20.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.12.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.7.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers) (3.0.9)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.6.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.12.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->huggingface-hub>=0.4.0->sentence-transformers) (3.8.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers) (7.1.2)\n"
          ]
        }
      ],
      "source": [
        "%pip install -U sentence-transformers rank_bm25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYS_FBeuoT2H",
        "outputId": "0461732d-0912-4e3f-d71b-4df4e1a2ac56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "what are neural networks\n"
          ]
        }
      ],
      "source": [
        "para = \"\"\"Neural networks, also known as artificial neural networks (ANNs) or simulated neural networks (SNNs), are a subset of machine learning and are at the heart of deep learning algorithms. Their name and structure are inspired by the human brain, mimicking the way that biological neurons signal to one another.\n",
        "\n",
        "Artificial neural networks (ANNs) are comprised of a node layers, containing an input layer, one or more hidden layers, and an output layer. Each node, or artificial neuron, connects to another and has an associated weight and threshold. If the output of any individual node is above the specified threshold value, that node is activated, sending data to the next layer of the network. Otherwise, no data is passed along to the next layer of the network.\n",
        "\n",
        "Neural networks rely on training data to learn and improve their accuracy over time. However, once these learning algorithms are fine-tuned for accuracy, they are powerful tools in computer science and artificial intelligence, allowing us to classify and cluster data at a high velocity. Tasks in speech recognition or image recognition can take minutes versus hours when compared to the manual identification by human experts. One of the most well-known neural networks is Google’s search algorithm.\n",
        "\n",
        "Once an input layer is determined, weights are assigned. These weights help determine the importance of any given variable, with larger ones contributing more significantly to the output compared to other inputs. All inputs are then multiplied by their respective weights and then summed. Afterward, the output is passed through an activation function, which determines the output. If that output exceeds a given threshold, it “fires” (or activates) the node, passing data to the next layer in the network. This results in the output of one node becoming in the input of the next node. This process of passing data from one layer to the next layer defines this neural network as a feedforward network.\n",
        "\n",
        "If we use the activation function from the beginning of this section, we can determine that the output of this node would be 1, since 6 is greater than 0. In this instance, you would go surfing; but if we adjust the weights or the threshold, we can achieve different outcomes from the model. When we observe one decision, like in the above example, we can see how a neural network could make increasingly complex decisions depending on the output of previous decisions or layers.\n",
        "\n",
        "In the example above, we used perceptrons to illustrate some of the mathematics at play here, but neural networks leverage sigmoid neurons, which are distinguished by having values between 0 and 1. Since neural networks behave similarly to decision trees, cascading data from one node to another, having x values between 0 and 1 will reduce the impact of any given change of a single variable on the output of any given node, and subsequently, the output of the neural network.\n",
        "\n",
        "Neural networks can be classified into different types, which are used for different purposes. While this isn’t a comprehensive list of types, the below would be representative of the most common types of neural networks that you’ll come across for its common use cases:\n",
        "\n",
        "The perceptron is the oldest neural network, created by Frank Rosenblatt in 1958.\n",
        "\n",
        "Feedforward neural networks, or multi-layer perceptrons (MLPs), are what we’ve primarily been focusing on within this article. They are comprised of an input layer, a hidden layer or layers, and an output layer. While these neural networks are also commonly referred to as MLPs, it’s important to note that they are actually comprised of sigmoid neurons, not perceptrons, as most real-world problems are nonlinear. Data usually is fed into these models to train them, and they are the foundation for computer vision, natural language processing, and other neural networks.\n",
        "\n",
        "Convolutional neural networks (CNNs) are similar to feedforward networks, but they’re usually utilized for image recognition, pattern recognition, and/or computer vision. These networks harness principles from linear algebra, particularly matrix multiplication, to identify patterns within an image.\n",
        "\n",
        "Recurrent neural networks (RNNs) are identified by their feedback loops. These learning algorithms are primarily leveraged when using time-series data to make predictions about future outcomes, such as stock market predictions or sales forecasting.\n",
        "\n",
        "Deep Learning and neural networks tend to be used interchangeably in conversation, which can be confusing. As a result, it’s worth noting that the “deep” in deep learning is just referring to the depth of layers in a neural network. A neural network that consists of more than three layers—which would be inclusive of the inputs and the output—can be considered a deep learning algorithm. A neural network that only has two or three layers is just a basic neural network.\n",
        "\n",
        "\"\"\"\n",
        "title = 'what are neural networks'\n",
        "print(title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnEeYU_8oT2I",
        "outputId": "bfb7f0fb-7814-41d8-a0de-b8cda48b5186"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Neural networks, also known as artificial neural networks (ANNs) or simulated neural networks (SNNs), are a subset of machine learning and are at the heart of deep learning algorithms.',\n",
              " 'Their name and structure are inspired by the human brain, mimicking the way that biological neurons signal to one another.',\n",
              " 'Artificial neural networks (ANNs) are comprised of a node layers, containing an input layer, one or more hidden layers, and an output layer.',\n",
              " 'Each node, or artificial neuron, connects to another and has an associated weight and threshold.',\n",
              " 'If the output of any individual node is above the specified threshold value, that node is activated, sending data to the next layer of the network.',\n",
              " 'Otherwise, no data is passed along to the next layer of the network.',\n",
              " 'Neural networks rely on training data to learn and improve their accuracy over time.',\n",
              " 'However, once these learning algorithms are fine-tuned for accuracy, they are powerful tools in computer science and artificial intelligence, allowing us to classify and cluster data at a high velocity.',\n",
              " 'Tasks in speech recognition or image recognition can take minutes versus hours when compared to the manual identification by human experts.',\n",
              " 'One of the most well-known neural networks is Google’s search algorithm.',\n",
              " 'Once an input layer is determined, weights are assigned.',\n",
              " 'These weights help determine the importance of any given variable, with larger ones contributing more significantly to the output compared to other inputs.',\n",
              " 'All inputs are then multiplied by their respective weights and then summed.',\n",
              " 'Afterward, the output is passed through an activation function, which determines the output.',\n",
              " 'If that output exceeds a given threshold, it “fires” (or activates) the node, passing data to the next layer in the network.',\n",
              " 'This results in the output of one node becoming in the input of the next node.',\n",
              " 'This process of passing data from one layer to the next layer defines this neural network as a feedforward network.',\n",
              " 'If we use the activation function from the beginning of this section, we can determine that the output of this node would be 1, since 6 is greater than 0.',\n",
              " 'In this instance, you would go surfing; but if we adjust the weights or the threshold, we can achieve different outcomes from the model.',\n",
              " 'When we observe one decision, like in the above example, we can see how a neural network could make increasingly complex decisions depending on the output of previous decisions or layers.',\n",
              " 'In the example above, we used perceptrons to illustrate some of the mathematics at play here, but neural networks leverage sigmoid neurons, which are distinguished by having values between 0 and 1.',\n",
              " 'Since neural networks behave similarly to decision trees, cascading data from one node to another, having x values between 0 and 1 will reduce the impact of any given change of a single variable on the output of any given node, and subsequently, the output of the neural network.',\n",
              " 'Neural networks can be classified into different types, which are used for different purposes.',\n",
              " 'While this isn’t a comprehensive list of types, the below would be representative of the most common types of neural networks that you’ll come across for its common use cases:\\n\\nThe perceptron is the oldest neural network, created by Frank Rosenblatt in 1958.',\n",
              " 'Feedforward neural networks, or multi-layer perceptrons (MLPs), are what we’ve primarily been focusing on within this article.',\n",
              " 'They are comprised of an input layer, a hidden layer or layers, and an output layer.',\n",
              " 'While these neural networks are also commonly referred to as MLPs, it’s important to note that they are actually comprised of sigmoid neurons, not perceptrons, as most real-world problems are nonlinear.',\n",
              " 'Data usually is fed into these models to train them, and they are the foundation for computer vision, natural language processing, and other neural networks.',\n",
              " 'Convolutional neural networks (CNNs) are similar to feedforward networks, but they’re usually utilized for image recognition, pattern recognition, and/or computer vision.',\n",
              " 'These networks harness principles from linear algebra, particularly matrix multiplication, to identify patterns within an image.',\n",
              " 'Recurrent neural networks (RNNs) are identified by their feedback loops.',\n",
              " 'These learning algorithms are primarily leveraged when using time-series data to make predictions about future outcomes, such as stock market predictions or sales forecasting.',\n",
              " 'Deep Learning and neural networks tend to be used interchangeably in conversation, which can be confusing.',\n",
              " 'As a result, it’s worth noting that the “deep” in deep learning is just referring to the depth of layers in a neural network.',\n",
              " 'A neural network that consists of more than three layers—which would be inclusive of the inputs and the output—can be considered a deep learning algorithm.',\n",
              " 'A neural network that only has two or three layers is just a basic neural network.']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "passage = sent_tokenize(para)\n",
        "print(len(passage))\n",
        "passage"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import json\n",
        "# from sentence_transformers import SentenceTransformer, CrossEncoder, util\n",
        "# import gzip\n",
        "# import os\n",
        "# import torch\n",
        "\n",
        "# if not torch.cuda.is_available():\n",
        "#     print(\"Warning: No GPU found. Please add GPU to your notebook\")\n",
        "\n",
        "\n",
        "# #We use the Bi-Encoder to encode all passages, so that we can use it with sematic search\n",
        "# bi_encoder = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1')\n",
        "# bi_encoder.max_seq_length = 256     #Truncate long passages to 256 tokens\n",
        "# top_k = 32                          #Number of passages we want to retrieve with the bi-encoder\n",
        "\n",
        "# #The bi-encoder will retrieve 100 documents. We use a cross-encoder, to re-rank the results list to improve the quality\n",
        "# cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
        "\n",
        "# # As dataset, we use Simple English Wikipedia. Compared to the full English wikipedia, it has only\n",
        "# # about 170k articles. We split these articles into paragraphs and encode them with the bi-encoder\n",
        "\n",
        "# wikipedia_filepath = 'simplewiki-2020-11-01.jsonl.gz'\n",
        "\n",
        "# if not os.path.exists(wikipedia_filepath):\n",
        "#     util.http_get('http://sbert.net/datasets/simplewiki-2020-11-01.jsonl.gz', wikipedia_filepath)\n",
        "\n",
        "# passages = []\n",
        "# with gzip.open(wikipedia_filepath, 'rt', encoding='utf8') as fIn:\n",
        "#     for line in fIn:\n",
        "#         data = json.loads(line.strip())\n",
        "\n",
        "#         #Add all paragraphs\n",
        "#         #passages.extend(data['paragraphs'])\n",
        "\n",
        "#         #Only add the first paragraph\n",
        "#         passages.append(data['paragraphs'][0])\n",
        "\n",
        "# print(\"Passages:\", len(passages))\n",
        "\n",
        "# # We encode all passages into our vector space. This takes about 5 minutes (depends on your GPU speed)\n",
        "# corpus_embeddings = bi_encoder.encode(passages, convert_to_tensor=True, show_progress_bar=True)"
      ],
      "metadata": {
        "id": "AdDfZxX9pDzG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(passages[:100])"
      ],
      "metadata": {
        "id": "07-jDhiQpk9V"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A critical distinction for your setup is symmetric vs. asymmetric semantic search:\n",
        "\n",
        "For **symmetric** semantic search your **query and the entries in your corpus are of about the same length** and have the same amount of content. An example would be searching for similar questions: Your query could for example be “How to learn Python online?” and you want to find an entry like “How to learn Python on the web?”. For symmetric tasks, you could potentially flip the query and the entries in your corpus.\n",
        "\n",
        "For **asymmetric** semantic search, you usually have a** short query** (like a question or some keywords) and you want to **find a longer paragraph** answering the query. An example would be a query like “What is Python” and you wand to find the paragraph “Python is an interpreted, high-level and general-purpose programming language. Python’s design philosophy …”. For asymmetric tasks, flipping the query and the entries in your corpus usually does not make sense."
      ],
      "metadata": {
        "id": "u4CoHTdi26Oy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "3bb8735fbbdd49efa225a11842778f8e",
            "be73088c83ec4cf3af84205a8a925057",
            "08ab92ba506d48499d1c0690457d5b1a",
            "05d4ec7905ad4987b176a6477bbe1d7d",
            "eb9f847130344ef981dbdffaf21bd287",
            "479b0cda307e45c6bf2a53aa7f55f038",
            "dd4ffaea376343abbf6e3635583ce1a8",
            "2a312fd017b34830b2f6ef2b39249c93",
            "696552e592c942c6b4e8252a619b6830",
            "d1cc7d7011d848aca15b003898251444",
            "afc913f0a9bb4fc093e4a5c0f59be14e"
          ]
        },
        "id": "Jgm34C4MoT2J",
        "outputId": "dcba9b06-b5de-4d60-f1e9-31281db6a71e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3bb8735fbbdd49efa225a11842778f8e"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer, CrossEncoder, util\n",
        "import os\n",
        "import torch\n",
        "\n",
        "if not torch.cuda.is_available():\n",
        "    print(\"Warning: No GPU found. Please add GPU to your notebook\")\n",
        "\n",
        "\n",
        "#We use the Bi-Encoder to encode all passages, so that we can use it with sematic search\n",
        "bi_encoder = SentenceTransformer('msmarco-distilbert-base-v4')\n",
        "bi_encoder.max_seq_length = 256     #Truncate long passages to 256 tokens\n",
        "top_k = 32                          #Number of passages we want to retrieve with the bi-encoder\n",
        "\n",
        "#The bi-encoder will retrieve 100 documents. We use a cross-encoder, to re-rank the results list to improve the quality\n",
        "cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
        "\n",
        "# We encode all passages into our vector space. This takes about 5 minutes (depends on your GPU speed)\n",
        "corpus_embeddings = bi_encoder.encode(passage, convert_to_tensor=True, show_progress_bar=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "e25e21fb76de43739bfd8a71dcf6ea6a",
            "8673d901340b496f8b83b4ec2696dbb2",
            "c886211827b84d82a038151cf9494152",
            "097eacfb73e448488113263ed7986362",
            "ed1bbf49904242a0adb889dfa5728cf6",
            "4606b064c65f4a6e90de2bfdea4e9947",
            "3d0c0f94344e40e1965da2a8a6e2bdad",
            "12a7a1abd5544d7b9c55313edeece5ff",
            "071038ff6ff64b9a84d4eb10092201ff",
            "bf706913b1f34796a40ae21bdc734d8e",
            "889c5c7954d548da886784213c7e7fe2"
          ]
        },
        "id": "RzU8xlV2oT2K",
        "outputId": "26d83833-1689-4796-b324-094825bebcfc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/36 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e25e21fb76de43739bfd8a71dcf6ea6a"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# We also compare the results to lexical search (keyword search). Here, we use \n",
        "# the BM25 algorithm which is implemented in the rank_bm25 package.\n",
        "\n",
        "from rank_bm25 import BM25Okapi\n",
        "from sklearn.feature_extraction import _stop_words\n",
        "import string\n",
        "from tqdm.autonotebook import tqdm\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# We lower case our text and remove stop-words from indexing\n",
        "def bm25_tokenizer(text):\n",
        "    tokenized_doc = []\n",
        "    for token in text.lower().split():\n",
        "        token = token.strip(string.punctuation)\n",
        "\n",
        "        if len(token) > 0 and token not in _stop_words.ENGLISH_STOP_WORDS:\n",
        "            tokenized_doc.append(token)\n",
        "    return tokenized_doc\n",
        "\n",
        "\n",
        "tokenized_corpus = []\n",
        "for psg in tqdm(passage):\n",
        "    tokenized_corpus.append(bm25_tokenizer(psg))\n",
        "\n",
        "bm25 = BM25Okapi(tokenized_corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lqadm20AoT2M",
        "outputId": "f3325348-2911-44fb-f35d-dd0cb38dd142"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['neural', 'networks', 'known', 'artificial', 'neural', 'networks', 'anns', 'simulated', 'neural', 'networks', 'snns', 'subset', 'machine', 'learning', 'heart', 'deep', 'learning', 'algorithms'], ['structure', 'inspired', 'human', 'brain', 'mimicking', 'way', 'biological', 'neurons', 'signal'], ['artificial', 'neural', 'networks', 'anns', 'comprised', 'node', 'layers', 'containing', 'input', 'layer', 'hidden', 'layers', 'output', 'layer'], ['node', 'artificial', 'neuron', 'connects', 'associated', 'weight', 'threshold'], ['output', 'individual', 'node', 'specified', 'threshold', 'value', 'node', 'activated', 'sending', 'data', 'layer', 'network'], ['data', 'passed', 'layer', 'network'], ['neural', 'networks', 'rely', 'training', 'data', 'learn', 'improve', 'accuracy', 'time'], ['learning', 'algorithms', 'fine-tuned', 'accuracy', 'powerful', 'tools', 'computer', 'science', 'artificial', 'intelligence', 'allowing', 'classify', 'cluster', 'data', 'high', 'velocity'], ['tasks', 'speech', 'recognition', 'image', 'recognition', 'minutes', 'versus', 'hours', 'compared', 'manual', 'identification', 'human', 'experts'], ['well-known', 'neural', 'networks', 'google’s', 'search', 'algorithm'], ['input', 'layer', 'determined', 'weights', 'assigned'], ['weights', 'help', 'determine', 'importance', 'given', 'variable', 'larger', 'ones', 'contributing', 'significantly', 'output', 'compared', 'inputs'], ['inputs', 'multiplied', 'respective', 'weights', 'summed'], ['afterward', 'output', 'passed', 'activation', 'function', 'determines', 'output'], ['output', 'exceeds', 'given', 'threshold', '“fires”', 'activates', 'node', 'passing', 'data', 'layer', 'network'], ['results', 'output', 'node', 'input', 'node'], ['process', 'passing', 'data', 'layer', 'layer', 'defines', 'neural', 'network', 'feedforward', 'network'], ['use', 'activation', 'function', 'beginning', 'section', 'determine', 'output', 'node', '1', '6', 'greater', '0'], ['instance', 'surfing', 'adjust', 'weights', 'threshold', 'achieve', 'different', 'outcomes', 'model'], ['observe', 'decision', 'like', 'example', 'neural', 'network', 'make', 'increasingly', 'complex', 'decisions', 'depending', 'output', 'previous', 'decisions', 'layers'], ['example', 'used', 'perceptrons', 'illustrate', 'mathematics', 'play', 'neural', 'networks', 'leverage', 'sigmoid', 'neurons', 'distinguished', 'having', 'values', '0', '1'], ['neural', 'networks', 'behave', 'similarly', 'decision', 'trees', 'cascading', 'data', 'node', 'having', 'x', 'values', '0', '1', 'reduce', 'impact', 'given', 'change', 'single', 'variable', 'output', 'given', 'node', 'subsequently', 'output', 'neural', 'network'], ['neural', 'networks', 'classified', 'different', 'types', 'used', 'different', 'purposes'], ['isn’t', 'comprehensive', 'list', 'types', 'representative', 'common', 'types', 'neural', 'networks', 'you’ll', 'come', 'common', 'use', 'cases', 'perceptron', 'oldest', 'neural', 'network', 'created', 'frank', 'rosenblatt', '1958'], ['feedforward', 'neural', 'networks', 'multi-layer', 'perceptrons', 'mlps', 'we’ve', 'primarily', 'focusing', 'article'], ['comprised', 'input', 'layer', 'hidden', 'layer', 'layers', 'output', 'layer'], ['neural', 'networks', 'commonly', 'referred', 'mlps', 'it’s', 'important', 'note', 'actually', 'comprised', 'sigmoid', 'neurons', 'perceptrons', 'real-world', 'problems', 'nonlinear'], ['data', 'usually', 'fed', 'models', 'train', 'foundation', 'computer', 'vision', 'natural', 'language', 'processing', 'neural', 'networks'], ['convolutional', 'neural', 'networks', 'cnns', 'similar', 'feedforward', 'networks', 'they’re', 'usually', 'utilized', 'image', 'recognition', 'pattern', 'recognition', 'and/or', 'computer', 'vision'], ['networks', 'harness', 'principles', 'linear', 'algebra', 'particularly', 'matrix', 'multiplication', 'identify', 'patterns', 'image'], ['recurrent', 'neural', 'networks', 'rnns', 'identified', 'feedback', 'loops'], ['learning', 'algorithms', 'primarily', 'leveraged', 'using', 'time-series', 'data', 'make', 'predictions', 'future', 'outcomes', 'stock', 'market', 'predictions', 'sales', 'forecasting'], ['deep', 'learning', 'neural', 'networks', 'tend', 'used', 'interchangeably', 'conversation', 'confusing'], ['result', 'it’s', 'worth', 'noting', '“deep”', 'deep', 'learning', 'just', 'referring', 'depth', 'layers', 'neural', 'network'], ['neural', 'network', 'consists', 'layers—which', 'inclusive', 'inputs', 'output—can', 'considered', 'deep', 'learning', 'algorithm'], ['neural', 'network', 'layers', 'just', 'basic', 'neural', 'network']]\n"
          ]
        }
      ],
      "source": [
        "print(tokenized_corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "MzIFlg97oT2M"
      },
      "outputs": [],
      "source": [
        "# This function will search all wikipedia articles for passage that\n",
        "# answer the query\n",
        "def bm25search(query):\n",
        "    print(\"Input question:\", query)\n",
        "\n",
        "    ##### BM25 search (lexical search) #####\n",
        "    bm25_scores = bm25.get_scores(bm25_tokenizer(query))\n",
        "    top_n = np.argpartition(bm25_scores, -5)[-5:]\n",
        "    bm25_hits = [{'corpus_id': idx, 'score': bm25_scores[idx]} for idx in top_n]\n",
        "    bm25_hits = sorted(bm25_hits, key=lambda x: x['score'], reverse=True)\n",
        "    \n",
        "    print(\"Top-5 lexical search (BM25) hits\")\n",
        "    for hit in bm25_hits[0:5]:\n",
        "        print(\"\\t{:.3f}\\t{}\".format(hit['score'], passage[hit['corpus_id']]))\n",
        "\n",
        "    ##### Re-Ranking #####\n",
        "    # Now, score all retrieved passage with the cross_encoder\n",
        "    cross_inp = [[query, passage[hit['corpus_id']]] for hit in bm25_hits]\n",
        "    cross_scores = cross_encoder.predict(cross_inp)\n",
        "\n",
        "    # Sort results by the cross-encoder scores\n",
        "    for idx in range(len(cross_scores)):\n",
        "        bm25_hits[idx]['cross-score'] = cross_scores[idx]\n",
        "\n",
        "    # Output of top-5 hits from re-ranker (BM25)\n",
        "    print(\"\\n-------------------------\\n\")\n",
        "    print(\"Top-5 Cross-Encoder Re-ranker hits\")\n",
        "    bm25_hits = sorted(bm25_hits, key=lambda x: x['cross-score'], reverse=True)\n",
        "    for hit in bm25_hits[0:5]:\n",
        "        print(\"\\t{:.3f}\\t{}\".format(hit['cross-score'], passage[hit['corpus_id']].replace(\"\\n\", \" \")))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8w3PlChoT2N",
        "outputId": "bbbcb4c1-680c-4c08-8388-8ce684ba93cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input question: what are neural networks\n",
            "Top-5 lexical search (BM25) hits\n",
            "\t1.549\tNeural networks, also known as artificial neural networks (ANNs) or simulated neural networks (SNNs), are a subset of machine learning and are at the heart of deep learning algorithms.\n",
            "\t1.352\tOne of the most well-known neural networks is Google’s search algorithm.\n",
            "\t1.287\tRecurrent neural networks (RNNs) are identified by their feedback loops.\n",
            "\t1.229\tNeural networks can be classified into different types, which are used for different purposes.\n",
            "\t1.201\tA neural network that only has two or three layers is just a basic neural network.\n",
            "\n",
            "-------------------------\n",
            "\n",
            "Top-5 Cross-Encoder Re-ranker hits\n",
            "\t10.222\tNeural networks, also known as artificial neural networks (ANNs) or simulated neural networks (SNNs), are a subset of machine learning and are at the heart of deep learning algorithms.\n",
            "\t7.343\tA neural network that only has two or three layers is just a basic neural network.\n",
            "\t5.397\tNeural networks can be classified into different types, which are used for different purposes.\n",
            "\t4.774\tRecurrent neural networks (RNNs) are identified by their feedback loops.\n",
            "\t4.752\tOne of the most well-known neural networks is Google’s search algorithm.\n"
          ]
        }
      ],
      "source": [
        "bm25search(query = title)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This function will search all wikipedia articles for passage that\n",
        "# answer the query\n",
        "def semanticsearch(query):\n",
        "    print(\"Input question:\", query)\n",
        "\n",
        "    ##### Sematic Search #####\n",
        "    # Encode the query using the bi-encoder and find potentially relevant passage\n",
        "    question_embedding = bi_encoder.encode(query, convert_to_tensor=True)\n",
        "    question_embedding = question_embedding.cuda()\n",
        "    hits = util.semantic_search(question_embedding, corpus_embeddings, top_k=top_k)\n",
        "    hits = hits[0]  # Get the hits for the first query\n",
        "\n",
        "    ##### Re-Ranking #####\n",
        "    # Now, score all retrieved passage with the cross_encoder\n",
        "    cross_inp = [[query, passage[hit['corpus_id']]] for hit in hits]\n",
        "    cross_scores = cross_encoder.predict(cross_inp)\n",
        "\n",
        "    # Sort results by the cross-encoder scores\n",
        "    for idx in range(len(cross_scores)):\n",
        "        hits[idx]['cross-score'] = cross_scores[idx]\n",
        "\n",
        "    # Output of top-5 hits from bi-encoder\n",
        "    print(\"\\n-------------------------\\n\")\n",
        "    print(\"Top-5 Bi-Encoder Retrieval hits\")\n",
        "    hits = sorted(hits, key=lambda x: x['score'], reverse=True)\n",
        "    for hit in hits[0:5]:\n",
        "        print(\"\\t{:.3f}\\t{}\".format(hit['score'], passage[hit['corpus_id']].replace(\"\\n\", \" \")))\n",
        "\n",
        "    # Output of top-5 hits from re-ranker (Semantic search)\n",
        "    print(\"\\n-------------------------\\n\")\n",
        "    print(\"Top-5 Cross-Encoder Re-ranker hits\")\n",
        "    hits = sorted(hits, key=lambda x: x['cross-score'], reverse=True)\n",
        "    for hit in hits[0:5]:\n",
        "        print(\"\\t{:.3f}\\t{}\".format(hit['cross-score'], passage[hit['corpus_id']].replace(\"\\n\", \" \")))"
      ],
      "metadata": {
        "id": "nlnZt68iynFg"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "semanticsearch(query = title)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzQZvyn6zq-V",
        "outputId": "cf941f7f-3b6b-4799-9ca8-ada623b5cfd1"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input question: what are neural networks\n",
            "\n",
            "-------------------------\n",
            "\n",
            "Top-5 Bi-Encoder Retrieval hits\n",
            "\t0.683\tNeural networks, also known as artificial neural networks (ANNs) or simulated neural networks (SNNs), are a subset of machine learning and are at the heart of deep learning algorithms.\n",
            "\t0.600\tNeural networks can be classified into different types, which are used for different purposes.\n",
            "\t0.593\tData usually is fed into these models to train them, and they are the foundation for computer vision, natural language processing, and other neural networks.\n",
            "\t0.566\tArtificial neural networks (ANNs) are comprised of a node layers, containing an input layer, one or more hidden layers, and an output layer.\n",
            "\t0.539\tA neural network that only has two or three layers is just a basic neural network.\n",
            "\n",
            "-------------------------\n",
            "\n",
            "Top-5 Cross-Encoder Re-ranker hits\n",
            "\t10.222\tNeural networks, also known as artificial neural networks (ANNs) or simulated neural networks (SNNs), are a subset of machine learning and are at the heart of deep learning algorithms.\n",
            "\t7.343\tA neural network that only has two or three layers is just a basic neural network.\n",
            "\t6.274\tArtificial neural networks (ANNs) are comprised of a node layers, containing an input layer, one or more hidden layers, and an output layer.\n",
            "\t5.756\tThis process of passing data from one layer to the next layer defines this neural network as a feedforward network.\n",
            "\t5.703\tNeural networks rely on training data to learn and improve their accuracy over time.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Rn7GDd-LuoqY"
      },
      "execution_count": 32,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.7.6 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "47c626452ef4ef3e74376d35c302fcf9bdc1b9327d6e04736eb914a557504e89"
      }
    },
    "colab": {
      "name": "part1_3.ipynb",
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3bb8735fbbdd49efa225a11842778f8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_be73088c83ec4cf3af84205a8a925057",
              "IPY_MODEL_08ab92ba506d48499d1c0690457d5b1a",
              "IPY_MODEL_05d4ec7905ad4987b176a6477bbe1d7d"
            ],
            "layout": "IPY_MODEL_eb9f847130344ef981dbdffaf21bd287"
          }
        },
        "be73088c83ec4cf3af84205a8a925057": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_479b0cda307e45c6bf2a53aa7f55f038",
            "placeholder": "​",
            "style": "IPY_MODEL_dd4ffaea376343abbf6e3635583ce1a8",
            "value": "Batches: 100%"
          }
        },
        "08ab92ba506d48499d1c0690457d5b1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a312fd017b34830b2f6ef2b39249c93",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_696552e592c942c6b4e8252a619b6830",
            "value": 2
          }
        },
        "05d4ec7905ad4987b176a6477bbe1d7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1cc7d7011d848aca15b003898251444",
            "placeholder": "​",
            "style": "IPY_MODEL_afc913f0a9bb4fc093e4a5c0f59be14e",
            "value": " 2/2 [00:00&lt;00:00, 17.08it/s]"
          }
        },
        "eb9f847130344ef981dbdffaf21bd287": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "479b0cda307e45c6bf2a53aa7f55f038": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd4ffaea376343abbf6e3635583ce1a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a312fd017b34830b2f6ef2b39249c93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "696552e592c942c6b4e8252a619b6830": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d1cc7d7011d848aca15b003898251444": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afc913f0a9bb4fc093e4a5c0f59be14e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e25e21fb76de43739bfd8a71dcf6ea6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8673d901340b496f8b83b4ec2696dbb2",
              "IPY_MODEL_c886211827b84d82a038151cf9494152",
              "IPY_MODEL_097eacfb73e448488113263ed7986362"
            ],
            "layout": "IPY_MODEL_ed1bbf49904242a0adb889dfa5728cf6"
          }
        },
        "8673d901340b496f8b83b4ec2696dbb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4606b064c65f4a6e90de2bfdea4e9947",
            "placeholder": "​",
            "style": "IPY_MODEL_3d0c0f94344e40e1965da2a8a6e2bdad",
            "value": "100%"
          }
        },
        "c886211827b84d82a038151cf9494152": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12a7a1abd5544d7b9c55313edeece5ff",
            "max": 36,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_071038ff6ff64b9a84d4eb10092201ff",
            "value": 36
          }
        },
        "097eacfb73e448488113263ed7986362": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf706913b1f34796a40ae21bdc734d8e",
            "placeholder": "​",
            "style": "IPY_MODEL_889c5c7954d548da886784213c7e7fe2",
            "value": " 36/36 [00:00&lt;00:00, 906.88it/s]"
          }
        },
        "ed1bbf49904242a0adb889dfa5728cf6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4606b064c65f4a6e90de2bfdea4e9947": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d0c0f94344e40e1965da2a8a6e2bdad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "12a7a1abd5544d7b9c55313edeece5ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "071038ff6ff64b9a84d4eb10092201ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bf706913b1f34796a40ae21bdc734d8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "889c5c7954d548da886784213c7e7fe2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}