{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cat sits outside \t\t The dog plays in the garden \t\t Score: 0.2838\n",
      "A man is playing guitar \t\t A woman watches TV \t\t Score: -0.0327\n",
      "The new movie is awesome \t\t The new movie is so great \t\t Score: 0.8939\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Two lists of sentences\n",
    "sentences1 = ['The cat sits outside',\n",
    "             'A man is playing guitar',\n",
    "             'The new movie is awesome']\n",
    "\n",
    "sentences2 = ['The dog plays in the garden',\n",
    "              'A woman watches TV',\n",
    "              'The new movie is so great']\n",
    "\n",
    "#Compute embedding for both lists\n",
    "embeddings1 = model.encode(sentences1, convert_to_tensor=True)\n",
    "embeddings2 = model.encode(sentences2, convert_to_tensor=True)\n",
    "\n",
    "#Compute cosine-similarities\n",
    "cosine_scores = util.cos_sim(embeddings1, embeddings2)\n",
    "\n",
    "#Output the pairs with their score\n",
    "for i in range(len(sentences1)):\n",
    "    print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(sentences1[i], sentences2[i], cosine_scores[i][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('data.df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Good morning Dr. Adams.', 'The patient is waiting for you in room number 3.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import tokenize\n",
    "p = \"Good morning Dr. Adams. The patient is waiting for you in room number 3.\"\n",
    "\n",
    "tokenize.sent_tokenize(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neural networks\n"
     ]
    }
   ],
   "source": [
    "# i = \n",
    "para = \"\"\"Deep learning is a hot topic these days. But what is it that makes it special and sets it apart from other aspects of machine learning? That is a deep question (pardon the pun). To even begin to answer it, we will need to learn the basics of neural networks.\n",
    "\n",
    "Neural networks are the workhorses of deep learning. And while they may look like black boxes, deep down (sorry, I will stop the terrible puns) they are trying to accomplish the same thing as any other model — to make good predictions.\n",
    "\n",
    "In this post, we will explore the ins and outs of a simple neural network. And by the end, hopefully you (and I) will have gained a deeper and more intuitive understanding of how neural networks do what they do.\n",
    "Let’s start with a really high level overview so we know what we are working with. Neural networks are multi-layer networks of neurons (the blue and magenta nodes in the chart below) that we use to classify things, make predictions, etc. Below is the diagram of a simple neural network with five inputs, 5 outputs, and two hidden layers of neurons.\n",
    "Starting from the left, we have:\n",
    "\n",
    "The input layer of our model in orange.\n",
    "Our first hidden layer of neurons in blue.\n",
    "Our second hidden layer of neurons in magenta.\n",
    "The output layer (aka the prediction) of our model in green.\n",
    "The arrows that connect the dots shows how all the neurons are interconnected and how data travels from the input layer all the way through to the output layer.\n",
    "\n",
    "Later we will calculate step by step each output value. We will also watch how the neural network learns from its mistake using a process known as backpropagation.\n",
    "\"\"\"\n",
    "title = 'neural networks'\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Deep learning is a hot topic these days.',\n",
       " 'But what is it that makes it special and sets it apart from other aspects of machine learning?',\n",
       " 'That is a deep question (pardon the pun).',\n",
       " 'To even begin to answer it, we will need to learn the basics of neural networks.',\n",
       " 'Neural networks are the workhorses of deep learning.',\n",
       " 'And while they may look like black boxes, deep down (sorry, I will stop the terrible puns) they are trying to accomplish the same thing as any other model — to make good predictions.',\n",
       " 'In this post, we will explore the ins and outs of a simple neural network.',\n",
       " 'And by the end, hopefully you (and I) will have gained a deeper and more intuitive understanding of how neural networks do what they do.',\n",
       " 'Let’s start with a really high level overview so we know what we are working with.',\n",
       " 'Neural networks are multi-layer networks of neurons (the blue and magenta nodes in the chart below) that we use to classify things, make predictions, etc.',\n",
       " 'Below is the diagram of a simple neural network with five inputs, 5 outputs, and two hidden layers of neurons.',\n",
       " 'Starting from the left, we have:\\n\\nThe input layer of our model in orange.',\n",
       " 'Our first hidden layer of neurons in blue.',\n",
       " 'Our second hidden layer of neurons in magenta.',\n",
       " 'The output layer (aka the prediction) of our model in green.',\n",
       " 'The arrows that connect the dots shows how all the neurons are interconnected and how data travels from the input layer all the way through to the output layer.',\n",
       " 'Later we will calculate step by step each output value.',\n",
       " 'We will also watch how the neural network learns from its mistake using a process known as backpropagation.']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents = tokenize.sent_tokenize(para)\n",
    "sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: \n",
      "\n",
      "Top 10 most similar sentences in corpus:\n",
      "The arrows that connect the dots shows how all the neurons are interconnected and how data travels from the input layer all the way through to the output layer. (Score: 0.0839)\n",
      "But what is it that makes it special and sets it apart from other aspects of machine learning? (Score: 0.0770)\n",
      "Our first hidden layer of neurons in blue. (Score: 0.0510)\n",
      "Neural networks are multi-layer networks of neurons (the blue and magenta nodes in the chart below) that we use to classify things, make predictions, etc. (Score: 0.0434)\n",
      "Later we will calculate step by step each output value. (Score: 0.0434)\n",
      "And while they may look like black boxes, deep down (sorry, I will stop the terrible puns) they are trying to accomplish the same thing as any other model — to make good predictions. (Score: 0.0337)\n",
      "The output layer (aka the prediction) of our model in green. (Score: 0.0240)\n",
      "That is a deep question (pardon the pun). (Score: 0.0217)\n",
      "Starting from the left, we have:\n",
      "\n",
      "The input layer of our model in orange. (Score: 0.0115)\n",
      "Let’s start with a really high level overview so we know what we are working with. (Score: 0.0040)\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "\n",
    "embedder = SentenceTransformer('msmarco-roberta-base-v3')\n",
    "\n",
    "corpus_embeddings = embedder.encode(sents, convert_to_tensor=True)\n",
    "\n",
    "# Query sentences:\n",
    "queries = ['']\n",
    "\n",
    "\n",
    "# Find the closest 5 sentences of the corpus for each query sentence based on cosine similarity\n",
    "top_k = min(10, len(sents))\n",
    "for query in queries:\n",
    "    query_embedding = embedder.encode(query, convert_to_tensor=True)\n",
    "\n",
    "    # We use cosine-similarity and torch.topk to find the highest 5 scores\n",
    "    cos_scores = util.cos_sim(query_embedding, corpus_embeddings)[0]\n",
    "    top_results = torch.topk(cos_scores, k=top_k)\n",
    "\n",
    "    print(\"\\n\\n======================\\n\\n\")\n",
    "    print(\"Query:\", query)\n",
    "    print(\"\\nTop 10 most similar sentences in corpus:\")\n",
    "\n",
    "    for score, idx in zip(top_results[0], top_results[1]):\n",
    "        print(sents[idx], \"(Score: {:.4f})\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "47c626452ef4ef3e74376d35c302fcf9bdc1b9327d6e04736eb914a557504e89"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
